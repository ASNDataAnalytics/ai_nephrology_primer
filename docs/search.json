[
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Important\n\n\n\nNote that LLMs are stochastic/non-deteriministic, so there are no definitive solutions."
  },
  {
    "objectID": "solutions.html#possible-solutions-to-exercises",
    "href": "solutions.html#possible-solutions-to-exercises",
    "title": "Solutions",
    "section": "Possible Solutions to Exercises",
    "text": "Possible Solutions to Exercises\n\nExercise 1\nPrompt: Use an LLM to clean data in preparation for analysis and modeling.\nPossible Solutions\n\nChatGPTClaudeGemini\n\n\nPrompt: You are Dr.Â Karandeep Singh, the creator of TidierOrg and Tidier.jl. You are an expert in coding, AI, and nephrology.\n[Objective] Clean messy clinical trial data to prepare for analysis and predictive modeling.\n[Context] Take this messy data {messy_aki.xlsx} and provide valid Julia code to accurately clean the data.\n[Constraints] You must use TidierOrg tools to clean the data.\n[Format] Return valid Julia code to read in the messy data, clean and validate the data, and export the data to a csv. Provide a report in markdown that catalogs missing data, outliers, and any edge cases that need HITL review before modeling. Clearly explain which Tidier.jl packages you are using and what each section of the code achieves with the resulting Julia code you generate. Do this in a manner for someone who is familiar with code but knows nothing about Julia. Provide key points for choosing Julia over other programming languages.\nResponse:\nJulia cleaning script (TidierOrg-first)\n\n############################################################\n# AKI trial data cleaning (TidierOrg / Tidier.jl workflow)\n# - Reads messy Excel\n# - Detects the true header row\n# - Cleans/standardizes fields (dates, categories, numerics)\n# - Validates + flags HITL edge cases\n# - Exports clean CSV + a markdown QA report\n############################################################\n\nusing Tidier                    # meta-package (re-exports TidierData, TidierFiles, TidierStrings, TidierDates, etc.)\nusing DataFrames\nusing Dates\nusing Statistics\n\n# -------------------------\n# 0) I/O paths\n# -------------------------\nin_path  = \"/mnt/data/messy_aki.xlsx\"\nout_csv  = \"aki_clean.csv\"\nout_md   = \"aki_cleaning_report.md\"\n\n# -------------------------\n# 1) Read Excel (TidierFiles)\n#    We read with col_names=false because the file has title rows above the real header\n# -------------------------\ndf_raw = TidierFiles.read_xlsx(in_path; sheet=1, col_names=false, trim_ws=true)\n\n# -------------------------\n# 2) Find the header row containing \"study_id\" in the first column, then re-read as data\n# -------------------------\nfirstcol = df_raw[:, 1]\nheader_row = findfirst(x -&gt; !ismissing(x) && lowercase(String(x)) == \"study_id\", firstcol)\n\nif header_row === nothing\n    error(\"Could not find a header row with 'study_id' in column 1. Inspect df_raw to locate headers.\")\nend\n\n# Extract header values and data rows\nhdr_vals = df_raw[header_row, :]\ndf = df_raw[(header_row + 1):nrow(df_raw), :]\n\n# Assign column names from the header row\nrename!(df, Symbol.(map(x -&gt; ismissing(x) ? \"\" : String(x), collect(hdr_vals))))\n\n# Drop any columns with empty names (common when there are blank columns in the sheet)\nempty_name_cols = names(df)[map(nm -&gt; nm == Symbol(\"\"), names(df))]\nif !isempty(empty_name_cols)\n    select!(df, Not(empty_name_cols))\nend\n\n# Clean column names to snake_case (TidierData)\ndf = @chain df begin\n    @clean_names()\nend\n\n# -------------------------\n# 3) Drop trailing note rows / non-data rows\n#    (in this file, rows with missing study_id are notes/permissions)\n# -------------------------\ndf = @chain df begin\n    @filter(!ismissing(study_id))\nend\n\n# -------------------------\n# 4) Helper parsers (used inside @mutate)\n# -------------------------\n# Extract the first number from messy strings like \"19 but poor collection\"\nfunction first_number(x)\n    if ismissing(x)\n        return missing\n    end\n    if x isa Number\n        return Float64(x)\n    end\n    s = strip(String(x))\n    m = match(r\"-?\\d+(\\.\\d+)?\", s)\n    return m === nothing ? missing : parse(Float64, m.match)\nend\n\n# Parse DOB from multiple common Excel/string formats\nfunction parse_dob(x)\n    if ismissing(x)\n        return missing\n    end\n    # Already a Date/DateTime\n    if x isa Date\n        return x\n    elseif x isa DateTime\n        return Date(x)\n    end\n\n    s = strip(String(x))\n    if isempty(s)\n        return missing\n    end\n\n    # Normalize month-name strings like \"may 5 1970\" -&gt; \"May 5 1970\"\n    s2 = join(uppercasefirst.(split(lowercase(s), ' ')), ' ')\n\n    # Try a few formats\n    for fmt in (dateformat\"y-m-d\", dateformat\"m/d/y\", dateformat\"u d y\", dateformat\"u d, y\")\n        try\n            return Date(s2, fmt)\n        catch\n        end\n    end\n\n    # Last resort: try Date(s2) (can work for some ISO-ish strings)\n    try\n        return Date(s2)\n    catch\n        return missing\n    end\nend\n\n# Standardize Yes/No-ish fields\nfunction yesno(x)\n    if ismissing(x)\n        return missing\n    end\n    s = lowercase(strip(String(x)))\n    if s in (\"yes\", \"y\", \"true\", \"1\")\n        return \"Yes\"\n    elseif s in (\"no\", \"n\", \"false\", \"0\")\n        return \"No\"\n    else\n        return missing\n    end\nend\n\n# Standardize sex\nfunction sex_std(x)\n    if ismissing(x)\n        return missing\n    end\n    s = lowercase(strip(String(x)))\n    if s in (\"m\", \"male\")\n        return \"Male\"\n    elseif s in (\"f\", \"female\")\n        return \"Female\"\n    else\n        return missing\n    end\nend\n\n# Standardize race (example mappingâ€”edit if your protocol uses different groupings)\nfunction race_std(x)\n    if ismissing(x)\n        return missing\n    end\n    s = lowercase(strip(String(x)))\n    if s in (\"white\", \"caucasian\", \"w\", \"white \")\n        return \"White\"\n    elseif s in (\"black\", \"af-am\", \"african american\", \"african-american\")\n        return \"Black\"\n    elseif s in (\"asian\")\n        return \"Asian\"\n    elseif s in (\"mixed\", \"multiracial\")\n        return \"Mixed\"\n    elseif s in (\"other\")\n        return \"Other\"\n    else\n        return \"Other\"\n    end\nend\n\n# Standardize Hispanic ethnicity with typo handling\nfunction hispanic_std(x)\n    if ismissing(x)\n        return missing\n    end\n    s = lowercase(strip(String(x)))\n    if s in (\"hispanic\", \"h\", \"h \", \"hisspanic\", \"hispannic\")\n        return \"Hispanic\"\n    elseif s in (\"not hispanic\", \"nh\", \"non-hispanic\", \"non hispanic\")\n        return \"Not Hispanic\"\n    else\n        return missing\n    end\nend\n\n# -------------------------\n# 5) Main cleaning transforms (TidierData)\n#    - Parse types\n#    - Keep â€œrawâ€ copies where useful for audit\n#    - Create QA flags for HITL review\n# -------------------------\ndf_clean = @chain df begin\n    @mutate(\n        # IDs\n        study_id = as_integer(study_id),\n\n        # DOB -&gt; Date\n        dob_raw = dob,\n        dob = ~parse_dob(dob),\n\n        # Demographics standardization\n        sex_raw = sex,\n        sex = ~sex_std(sex),\n\n        race_raw = race,\n        race = ~race_std(race),\n\n        hispanic_raw = hispanic,\n        hispanic = ~hispanic_std(hispanic),\n\n        # GFR numerics (keep raw columns + parsed numeric columns)\n        admission_gfr_raw = admission_gfr,\n        day_1_gfr_raw      = day_1_gfr,\n        day2gfr_raw        = day2gfr,\n        day_3_gfr_raw      = day_3_gfr,\n        day_4_gfr_raw      = day_4_gfr,\n        day5_gfr_raw       = day5_gfr,\n\n        admission_gfr = ~first_number(admission_gfr),\n        day_1_gfr     = ~first_number(day_1_gfr),\n        day2_gfr      = ~first_number(day2gfr),\n        day_3_gfr     = ~first_number(day_3_gfr),\n        day_4_gfr     = ~first_number(day_4_gfr),\n        day5_gfr      = ~first_number(day5_gfr),\n\n        # Flags: â€œhad extra textâ€ (e.g., \"19 but poor collection\")\n        day2_parse_note = !(ismissing(day2gfr_raw)) && !(String(day2gfr_raw) |&gt; strip |&gt; x -&gt; occursin(r\"^-?\\d+(\\.\\d+)?$\", x)),\n\n        # Devices\n        hd_catheter_raw = hd_catheter,\n        hd_catheter = ~yesno(hd_catheter),\n\n        av_fistula_raw = av_fistula,\n        av_fistula = ~yesno(av_fistula)\n    ) |&gt;\n\n    # Keep a tidy column order (optional)\n    @select(\n        study_id, dob, sex, race, hispanic,\n        admission_gfr, day_1_gfr, day2_gfr, day_3_gfr, day_4_gfr, day5_gfr,\n        diagnosis, sediment, hd_catheter, av_fistula,\n        day2_parse_note,\n        # audit columns at the end\n        dob_raw, sex_raw, race_raw, hispanic_raw,\n        admission_gfr_raw, day_1_gfr_raw, day2gfr_raw, day_3_gfr_raw, day_4_gfr_raw, day5_gfr_raw,\n        hd_catheter_raw, av_fistula_raw\n    )\nend\n\n# -------------------------\n# 6) Validation + HITL flags\n# -------------------------\n\n# Duplicated study_id check\ndup_ids = @chain df_clean begin\n    @count(study_id)\n    @filter(n &gt; 1)\nend\n\n# Missingness summary\nmissing_summary = DataFrame(\n    column = String[],\n    n_missing = Int[],\n    pct_missing = Float64[]\n)\nfor nm in names(df_clean)\n    col = df_clean[!, nm]\n    nmiss = count(ismissing, col)\n    push!(missing_summary, (String(nm), nmiss, round(100 * nmiss / nrow(df_clean); digits=1)))\nend\n\n# Outlier thresholds (IQR rule) for each GFR column\ngfr_cols = [:admission_gfr, :day_1_gfr, :day2_gfr, :day_3_gfr, :day_4_gfr, :day5_gfr]\n\nfunction iqr_bounds(v::Vector{Union{Missing, Float64}})\n    x = collect(skipmissing(v))\n    if length(x) &lt; 4\n        return (missing, missing)  # too few points\n    end\n    q1 = quantile(x, 0.25)\n    q3 = quantile(x, 0.75)\n    iqr = q3 - q1\n    return (q1 - 1.5*iqr, q3 + 1.5*iqr)\nend\n\noutlier_rows = DataFrame()\nfor c in gfr_cols\n    lo, hi = iqr_bounds(df_clean[!, c])\n    if !(ismissing(lo) || ismissing(hi))\n        tmp = @chain df_clean begin\n            @mutate(_col = String(c), _lo = lo, _hi = hi)\n            @filter(!ismissing($(c)) && (($(c) &lt; lo) || ($(c) &gt; hi)))\n            @select(study_id, _col, $(c), _lo, _hi)\n        end\n        outlier_rows = vcat(outlier_rows, tmp; cols=:union)\n    end\nend\n\n# Extra clinical sanity flags (edit thresholds to your protocol)\nsanity_flags = @chain df_clean begin\n    @mutate(\n        flag_dob_unparsed = ismissing(dob),\n        flag_gfr_negative = any.((admission_gfr, day_1_gfr, day2_gfr, day_3_gfr, day_4_gfr, day5_gfr) .&lt; 0),\n        flag_gfr_very_high = any.((admission_gfr, day_1_gfr, day2_gfr, day_3_gfr, day_4_gfr, day5_gfr) .&gt; 200),\n        flag_day3_missing = ismissing(day_3_gfr),\n        flag_day2_note = day2_parse_note\n    )\nend\n\n# -------------------------\n# 7) Export clean CSV (TidierFiles)\n# -------------------------\nTidierFiles.write_csv(df_clean, out_csv)\n\n# -------------------------\n# 8) Write a markdown QA report\n# -------------------------\nfunction df_to_md_table(d::DataFrame; max_rows::Int=50)\n    n = min(nrow(d), max_rows)\n    cols = names(d)\n    header = \"|\" * join(string.(cols), \"|\") * \"|\\n\"\n    sep    = \"|\" * join(fill(\"---\", length(cols)), \"|\") * \"|\\n\"\n    rows = \"\"\n    for i in 1:n\n        vals = [ismissing(d[i, c]) ? \"missing\" : string(d[i, c]) for c in cols]\n        rows *= \"|\" * join(vals, \"|\") * \"|\\n\"\n    end\n    if nrow(d) &gt; max_rows\n        rows *= \"\\n*(truncated to first $(max_rows) rows)*\\n\"\n    end\n    return header * sep * rows\nend\n\nreport = \"\"\"\n# AKI Data Cleaning QA Report\n\n## Files\n- Input: `$(in_path)`\n- Output CSV: `$(out_csv)`\n\n## Row counts\n- Rows after header detection + dropping note rows: **$(nrow(df_clean))**\n- Columns: **$(ncol(df_clean))**\n\n## Missing data (all columns)\n$(df_to_md_table(sort(missing_summary, :n_missing, rev=true)))\n\n## Duplicate study IDs (requires HITL)\n$(nrow(dup_ids) == 0 ? \"_None detected._\" : df_to_md_table(dup_ids))\n\n## Parsed-text notes (e.g., GFR cell had extra text)\nRows with `day2_parse_note = true` should be reviewed to confirm the numeric extraction matches intent.\n$(df_to_md_table(@chain df_clean begin\n    @filter(day2_parse_note == true)\n    @select(study_id, day2gfr_raw, day2_gfr)\nend))\n\n## Outliers by IQR rule (requires HITL)\n$(nrow(outlier_rows) == 0 ? \"_None detected by IQR rule._\" : df_to_md_table(outlier_rows))\n\n## Sanity flags (requires HITL)\n$(df_to_md_table(@chain sanity_flags begin\n    @filter(flag_dob_unparsed || flag_gfr_very_high || flag_day3_missing || flag_day2_note)\n    @select(study_id, flag_dob_unparsed, flag_gfr_very_high, flag_day3_missing, flag_day2_note,\n            admission_gfr, day_1_gfr, day2_gfr, day_3_gfr, day_4_gfr, day5_gfr,\n            dob_raw)\nend))\n\"\"\"\n\nopen(out_md, \"w\") do io\n    write(io, report)\nend\n\nprintln(\"Wrote clean CSV -&gt; $(out_csv)\")\nprintln(\"Wrote QA report -&gt; $(out_md)\")\n\nWhat TidierOrg packages this uses (and why)\n\nTidier.jl (meta-package): loads the â€œtidyverse-likeâ€ ecosystem in one import. Tidier.jl is designed as a meta-package that re-exports functionality from smaller TidierOrg packages.\nTidierFiles.jl: provides read_xlsx() and write_csv() with a consistent â€œreadr/readxl-ishâ€ API, powered by XLSX.jl/CSV.jl under the hood.\nTidierData.jl: provides tidy macros like @chain, @mutate, @filter, @select, and @clean_names() for dplyr/tidyr-like transformations.\n\nMarkdown QA report (based on this messy_aki.xlsx)\nSummary\n\nExcel rows: 27 total on the sheet\nTrue data table rows: 23 (after skipping title/header junk)\nNon-data note rows removed: 3 (permission/notes at bottom with missing study_id)\nFinal analytic rows: 20\nKey HITL items: duplicate study IDs, extreme/implausible GFR values, one missing Day 3 GFR, â€œnumeric-with-textâ€ cell.\n\nMissing data\n\nday_3_gfr: 1 missing (study_id 21)\n\nOutliers (needs HITL review)\nUsing an IQR rule on the numeric-parsed GFR values, these stand out:\n\nAdmission GFR = 232 (study_id 20) â€” likely a data entry error (e.g., â€œ23.2â€ or â€œ23â€?) given subsequent days are ~19â€“33.\nAdmission GFR = 177 (study_id 21) â€” unusually high vs cohort; may be real or a typo (â€œ17.7â€ / â€œ17â€?).\nDay 1 GFR = 322 (study_id 15) â€” almost certainly a typo (pattern suggests â€œ32â€).\n\nEdge cases / messy-field normalization\n\nDOB includes a free-text date (\"may 5 1970\") that must be parsed carefully (the script handles multiple formats).\nSex mixes Male/Female with M/F and trailing whitespace.\nRace mixes casing and abbreviations (WHITE, Af-Am, Caucasian, etc.).\nHispanic includes typos (Hisspanic, Hispannic, H) and shorthand (NH).\nDay2 GFR contains at least one cell like \"19 but poor collection\"; the script extracts the first numeric value (=19) and flags it (day2_parse_note=true) for review.\n\nID integrity (must resolve before modeling)\n\nDuplicate study_id: 3 appears twice; 8 appears twice.\nThese represent clearly different patients/records and should be reconciled (true duplicates vs mis-keyed IDs) before train/test splits.\n\nHow to read the Julia code if you â€œknow code but not Juliaâ€\n\nusing Tidier is like library(tidyverse)â€”it brings in the TidierOrg ecosystem.\n@chain df begin ... end is like %&gt;% in R or method-chaining in Python; it pipes a DataFrame through steps.\n@mutate(new = f(old)) creates/overwrites columns.\nmissing is Juliaâ€™s NA.\nThe ~ prefix inside TidierData macros tells TidierData not to auto-vectorize a function (important when youâ€™re calling helper functions that should run â€œper-cellâ€ rather than being broadcast in a surprising way).\n\nWhy choose Julia here (vs Python/R) â€” the practical version\n\nSpeed without giving up expressiveness: you can do heavy feature engineering and modeling in one language without â€œtwo-languageâ€ rewrites.\nComposable, high-performance tabular + ML stack: DataFrames + MLJ/Flux/etc. can stay fast as the pipeline grows.\nTidyverse-like ergonomics (TidierOrg): if your team thinks in dplyr verbs, TidierData lowers the adoption cost while staying Julia-native.\n\nIf you want, I can adapt the race/ethnicity mappings and the GFR plausibility thresholds to match your trialâ€™s data dictionary / SAP (e.g., â€œUnknownâ€ handling, allowable ranges, and whether GFR is eGFR vs measured clearance).\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\nHereâ€™s a well-commented cleaning script that tackles every issue I spotted:\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom dateutil import parser as dateparser\nimport re\n\n# â”€â”€ 1. Load, skip the 3-row title block, drop the empty column F â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndf = pd.read_excel(\"messy_aki.xlsx\", skiprows=4, header=0)\ndf = df.drop(columns=[df.columns[5]])          # unnamed empty column between Hispanic and Admission GFR\ndf = df.dropna(how=\"all\")                       # drop fully-empty rows (incl. footer notes)\n\n# â”€â”€ 2. Standardise column names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndf.columns = [\n    \"study_id\", \"dob\", \"race\", \"sex\", \"hispanic\",\n    \"gfr_admission\", \"gfr_day1\", \"gfr_day2\", \"gfr_day3\", \"gfr_day4\", \"gfr_day5\",\n    \"diagnosis\", \"sediment\", \"hd_catheter\", \"av_fistula\"\n]\n\n# â”€â”€ 3. Duplicate / invalid study IDs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# IDs 3 and 8 appear twice; IDs 9, 10, 18 are missing entirely.\n# Flag duplicates so you can review â€” don't silently drop them.\ndf[\"duplicate_id_flag\"] = df.duplicated(subset=\"study_id\", keep=False)\n\n# â”€â”€ 4. Parse dates of birth â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef parse_dob(val):\n    if pd.isna(val):\n        return pd.NaT\n    if isinstance(val, pd.Timestamp):\n        return val\n    # Handle obvious typo like \"5=11-1984\"\n    val = str(val).replace(\"=\", \"-\")\n    try:\n        return dateparser.parse(val, dayfirst=False)\n    except Exception:\n        return pd.NaT\n\ndf[\"dob\"] = pd.to_datetime(df[\"dob\"].apply(parse_dob), errors=\"coerce\")\n\n# â”€â”€ 5. Standardise race â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nrace_map = {\n    \"caucasian\": \"White\",\n    \"white\":     \"White\",\n    \"af-am\":     \"Black\",\n    \"black\":     \"Black\",\n    \"asian\":     \"Asian\",\n    \"mixed\":     \"Other\",\n    \"other\":     \"Other\",\n}\ndf[\"race\"] = (df[\"race\"]\n              .str.strip()\n              .str.lower()\n              .map(race_map)\n              .fillna(\"Unknown\"))\n\n# â”€â”€ 6. Standardise sex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef clean_sex(val):\n    if pd.isna(val):\n        return np.nan\n    v = str(val).strip().lower()\n    if v in (\"male\", \"m\"):\n        return \"Male\"\n    if v in (\"female\", \"f\"):\n        return \"Female\"\n    return np.nan\n\ndf[\"sex\"] = df[\"sex\"].apply(clean_sex)\n\n# â”€â”€ 7. Standardise hispanic ethnicity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef clean_hispanic(val):\n    if pd.isna(val):\n        return np.nan\n    v = str(val).strip().lower().replace(\" \", \"\")\n    if v in (\"hispanic\", \"h\", \"hispannic\", \"hisspanic\"):   # typos\n        return \"Hispanic\"\n    if v in (\"nothispanic\", \"nh\"):\n        return \"Not Hispanic\"\n    return np.nan\n\ndf[\"hispanic\"] = df[\"hispanic\"].apply(clean_hispanic)\n\n# â”€â”€ 8. Clean GFR columns â€” coerce text to numeric, flag outliers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ngfr_cols = [\"gfr_admission\", \"gfr_day1\", \"gfr_day2\", \"gfr_day3\", \"gfr_day4\", \"gfr_day5\"]\n\ndef extract_numeric(val):\n    \"\"\"Pull the first number out of a cell; return NaN if none found.\"\"\"\n    if pd.isna(val):\n        return np.nan\n    try:\n        return float(val)\n    except (ValueError, TypeError):\n        match = re.search(r\"\\d+\\.?\\d*\", str(val))\n        return float(match.group()) if match else np.nan\n\nfor col in gfr_cols:\n    df[col] = df[col].apply(extract_numeric)\n\n# Flag physiologically implausible GFR values (&gt; 200 are likely data-entry errors)\nGFR_MAX = 200\nfor col in gfr_cols:\n    flag_col = col + \"_outlier_flag\"\n    df[flag_col] = df[col] &gt; GFR_MAX\n\n# â”€â”€ 9. Standardise Yes/No columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndef clean_yesno(val):\n    if pd.isna(val):\n        return np.nan\n    v = str(val).strip().lower().replace(\"`\", \"\")   # \"No`\" typo\n    if v == \"yes\":\n        return \"Yes\"\n    if v == \"no\":\n        return \"No\"\n    return np.nan\n\nfor col in [\"hd_catheter\", \"av_fistula\"]:\n    df[col] = df[col].apply(clean_yesno)\n\n# â”€â”€ 10. Standardise sediment free-text (minor normalisation) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndf[\"sediment\"] = (df[\"sediment\"]\n                  .str.strip()\n                  .str.lower()\n                  .str.replace(r\"\\s+\", \" \", regex=True)\n                  .str.replace(\"epi cell\", \"epithelial cell\")\n                  .str.replace(\"gran \", \"granular \"))\n\n# â”€â”€ 11. Report a cleaning summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"=== Cleaning summary ===\")\nprint(f\"Rows: {len(df)}\")\nprint(f\"\\nDuplicate study IDs:\\n{df[df['duplicate_id_flag']][['study_id','dob','diagnosis']]}\")\nprint(f\"\\nUnparseable DOBs: {df['dob'].isna().sum()}\")\nprint(f\"\\nGFR outlier flags:\")\nfor col in gfr_cols:\n    n = df[col + \"_outlier_flag\"].sum()\n    if n:\n        print(f\"  {col}: {n} outlier(s) â€” {df.loc[df[col+'_outlier_flag'], ['study_id', col]].values.tolist()}\")\n\nprint(f\"\\nSex nulls after cleaning:      {df['sex'].isna().sum()}\")\nprint(f\"Hispanic nulls after cleaning: {df['hispanic'].isna().sum()}\")\nprint(f\"Race unknowns:                 {(df['race']=='Unknown').sum()}\")\n\n# â”€â”€ 12. Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndf.to_csv(\"aki_clean.csv\", index=False)\nprint(\"\\nSaved to aki_clean.csv\")\n\n\n=== Cleaning summary ===\nRows: 22\n\nDuplicate study IDs:\n    study_id        dob           diagnosis\n2        3.0 1970-05-05        bleeding out\n3        3.0 1981-06-03  norovirus diarrhea\n8        8.0 1982-04-22     C diff diarrhea\n9        8.0 2003-10-12           NSAID tox\n21       NaN        NaT                 NaN\n22       NaN        NaT                 NaN\n\nUnparseable DOBs: 2\n\nGFR outlier flags:\n  gfr_admission: 1 outlier(s) â€” [[20.0, 232.0]]\n  gfr_day1: 1 outlier(s) â€” [[15.0, 322.0]]\n\nSex nulls after cleaning:      2\nHispanic nulls after cleaning: 2\nRace unknowns:                 2\n\nSaved to aki_clean.csv\nHereâ€™s a rundown of every issue it handles:\nStructure â€” skips the 3-row title block (â€œAcute Kidney Injury Studyâ€, resident name, project name) and the stray empty column between Hispanic and Admission GFR.\nColumn names â€” normalises the wildly inconsistent headers (DAY2GFR\\``,day 3 GfR`, etc.) to snake_case.\nDuplicate IDs â€” study_ids 3 and 8 each appear twice (and 9, 10, 18 are missing). The script flags duplicates rather than silently dropping them, since youâ€™ll need to decide which row is correct.\nDates of birth â€” handles three formats: Excel dates, â€œmay 5 1970â€ (free text), and â€œ5=11-1984â€ (typo with = instead of -).\nRace â€” merges â€œCaucasianâ€/â€œWHITEâ€/â€œwhiteâ€ â†’ â€œWhiteâ€, â€œAf-Amâ€/â€œBlackâ€ â†’ â€œBlackâ€, etc.\nSex â€” normalises â€œMâ€, â€œFâ€, â€œMaleâ€, â€œFemaleâ€, â€œFâ€ â†’ consistent â€œMaleâ€/â€œFemaleâ€.\nHispanic â€” fixes typos (â€œHispannicâ€, â€œHisspanicâ€) and abbreviations (â€œHâ€, â€œNHâ€).\nGFR values â€” row 2 has â€œ19 but poor collectionâ€ (extracts 19), and several rows have values like 322 or 232 that are almost certainly data-entry errors (extra digit). Those are flagged with outlier columns.\nYes/No fields â€” handles â€œYESâ€, â€œNOâ€, â€œNo`â€ (backtick typo) â†’ â€œYesâ€/â€œNoâ€.\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n#| eval: false\n\n\n\n\n\n\nExercise 2\nPrompt: Use an LLM to clean data in preparation for analysis and modeling.\nPossible Solutions\n\nChatGPTClaudeGemini\n\n\nPrompt: can you show me some python code to clean this data up?\n\nResponse:\n#| eval: false\n\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n#| eval: false\n\n\n\n\n\n\nExercise 3\nPrompt: Use an LLM to clean data in preparation for analysis and modeling.\nPossible Solutions\n\nChatGPTClaudeGemini\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n#| eval: false\n\n\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n\n\nPrompt: can you show me some python code to clean this data up?\nResponse:\n#| eval: false"
  },
  {
    "objectID": "literature.html",
    "href": "literature.html",
    "title": "Literature",
    "section": "",
    "text": "CJASN SeriesASN Task ForcePredictive ModelingDiet/NutritionResearchVisionClinical\n\n\n\nArtificial Intelligence and Machine Learning in Dialysis Ready for Prime Time?\nKotanko P, Zhang H, Wang Y  Clinical Journal of the American Society of Nephrology, 2023.  DOI: 10.2215/CJN.0000000000000089\n\n\nApplication of Natural Language Processing in Nephrology Research\nDouglas F, Chan L.  Clinical Journal of the American Society of Nephrology, 2023.  DOI: 10.2215/CJN.0000000000000118\n\n\n\n\n[Responsible Use of Artificial Intelligence to Improve Kidney Care\nA Statement from the American Society of Nephrology](https://journals.lww.com/jasn/fulltext/9900/responsible_use_of_artificial_intelligence_to.826.aspx){target=â€™_blankâ€™}\nTangri N, Cheungpasitporn W, Crittenden SD, Fornoni A, Peralta CA, Singh K, Usvyat LA, Waterman AD  Journal of the American Society of Nephrology, 2025.  DOI: 10.1681/ASN.0000000929\n\n\n\n\nHome Dialysis Prediction Using Artificial Intelligence\nMonaghan CK, Willetts J, Han H, Chaudhuri S, Ficociello LH, Kraus MA, 3 Giles HE, Usvyat L, Turk J  Kidney Medicine, 2025.  DOI: 10.1016/j.xkme.2024.100949\n\n\nArtificial intelligence in kidney disease and dialysis: from data mining to clinical impact\nNeri L, Zhang H, Usvyat LA.  Current Opinion in Nephrology and Hypertension, 2026.  DOI: 10.1097/MNH.0000000000001132\n\n\nEvaluation of performance measures in predictive artificial intelligence models to support medical decisions: overview and guidance\nVan Calster B, Collins GS, Vickers AJ, Wynants L, Kerr KF, BarreÃ±ada L, Varoquaux G, Singh K, Moons KGM, Hernandez-Boussard T, Timmerman D, McLernon DJ, Smeden Mvan, Steyerberg EW  Lancet Digit Health, 2025.  DOI: /10.1016/j.landig.2025.100916\n\n\nProspective comparison of econometric, machine learning, and foundation models for forecasting emergency department boarding patients\nPoursoltan L, Cao J, Clay B, Trimble B, Adrid L, Pan J, Chua A, Bell J, Longhurst CA, Zhu K, Singh K  npj Health Systems, 2025.  DOI: 10.1038/s44401-025-00054-z\n\n\nEvaluation of electronic health record-integrated artificial intelligence chart review\nKahl NM, Frieden MJ, Pope ZR, Millen MM, Tolia VM, Chan TC, Longhurst CA, Singh K, You AX  npj Health Systems, 2026.  DOI: 10.1038/s44401-025-00064-x\n\n\nGeneralizability of an acute kidney injury prediction model across health systems\nCao J, Zhang X, Shahinian V, Yin H, Steffick D, Saran R, Crowley S, Mathis M, Nadkarni GN, Heung M, Singh K  Nature Machine Intelligence, 2022.  DOI: 10.1038/s42256-022-00563-8\n\n\nSystematic Review and Meta-Analysis of Machine Learning Models for Acute Kidney Injury Risk Classification\nCama-Olivares A, Braun C, Takeuchi T, Oâ€™Hagan EC, Kaiser KA, Ghazi L, Chen J, Forni LG, Kane-Gill SL, Ostermann M, Shickel B, Ninan J, Neyra JA  Journal of the American Society of Nephrology, 2025.  DOI: 10.1681/ASN.0000000702\n\n\nMulticenter Development and Validation of a Multimodal Deep Learning Model to Predict Moderate to Severe AKI\nKoyner JL, Martin J, Carey KA, Caskey J, Edelson DP, Mayampurath A, Dligach D, Afshar M, ChurpekMM  Clinical Journal of the American Society of Nephrology, 2025.  DOI: 10.2215/CJN.0000000695\n\n\n\n\nFrom bytes to bites: application of large language models to enhance nutritional recommendations\nBergling K, Wang LC, Shivakumar O, Nandorine Ban A, Moore LW, Ginsberg N, Kooman J, Duncan N, Kotanko P, Zhang H  Clinical Kidney Journal, 2025.  DOI: 10.1093/ckj/sfaf082\n\n\nApplication of ChatGPT to Support Nutritional Recommendations for Dialysis Patients â€“ A Qualitative and Quantitative Evaluation\nWang L, Zhang H, Ginsberg N, Ban AN, Kooman JP, Kotanko P  Journal of Renal Nutrition, 2024.  DOI: 10.1053/j.jrn.2024.09.001\n\n\n\n\nPerformance of GPT-4 Vision on kidney pathology exam questions\nMiao J, Thongprayoon C, Cheungpasitporn W, Cornell LD  Am J Clin Pathol, 2024.  DOI: 10.1093/ajcp/aqae030\n\n\nThe dawn of multimodal artificial intelligence in nephrology\nShickel B, Bihorac A  Nature Reviews Nephrology, 2024.  DOI: 10.1038/s41581-023-00799-6\n\n\n\n\nIdentification of kidney-related medications using AI from self-captured pill images\nSheikh MS, Dreesman B, Barreto EF, Thongprayoon C, Miao J, Suppadungsuk S, Mao MA, Qureshi F, Pham JH, Craici IM, Kashani KB, Cheungpasitporn W  Ren Fail, 2024.  DOI: 10.1080/0886022X.2024.2402075\n\n\nImaging and spatially resolved mass spectrometry applications in nephrology\nGorman BL, Shafer CC, Ragi N, Sharma K, Neumann EK, Anderton CR  Nature Reviews Nephrology, 2025.  DOI: 10.1038/s41581-025-00946-1\n\n\n[Non-invasive biopsy diagnosis of diabetic kidney disease via deep learning applied to retinal images: a population-based study\n](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(25)00040-8/fulltext){target=â€™_blankâ€™}\nMeng Z, Guan Z, Yu S, Wu Y, Zhao Y, Shen J, et al.  The Lancet Digital Health, 2025.  DOI: 10.1016/j.landig.2025.02.008\n\n\n\n\nClinical Applications of Artificial Intelligence in Autosomal Dominant Polycystic Kidney Disease\nEbrahimi N, Cheungpasitporn W, Chebib FT, Borghol AHamid, Ghozloujeh ZGholizadeh, Norouzi S, Abdipour A  Nephrol Dial Transplant, 2026.  DOI: 10.1093/ndt/gfag010\n\n\nAI Scribes Are Not Productivity Tools (Yet)\nKim E, Liu VX, Singh K  NEJM, 2025.  DOI: 10.1056/AIe2501051\n\n\nArtificial Intelligence in Nephrology: Clinical Applications and Challenges\nSingh P, Goyal L, Mallick DC, Surani SR, Kaushik N, Chandramohan D, Simhadri PK  Kidney Medicine, 2025.  DOI: 10.1016/j.xkme.2024.100927"
  },
  {
    "objectID": "exercises.html",
    "href": "exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Note\n\n\n\nOptional: Use Google Colab to evaluate Python, Julia, and/or R code generated by the LLM. Select your programming language at Runtime &gt; Change runtime type &gt; [Python3 | R | Julia], paste the code in a cell, then click the Run Button. (NB: A Google account is required for Google Colab access.)"
  },
  {
    "objectID": "exercises.html#exercise-1-handling-messy-data",
    "href": "exercises.html#exercise-1-handling-messy-data",
    "title": "Exercises",
    "section": "Exercise 1: Handling Messy Data",
    "text": "Exercise 1: Handling Messy Data\nUse an LLM to clean data in preparation for analysis and modeling.\n\nDownload the messy_aki dataset from Dr.Â Peter Higginsâ€™ {medicaldata} R package.\n\nPrompt an LLM to write code to clean the data.\nEvaluate the results and adjust your prompt to address any missed issues.\n\nData: messy_aki\nOptional Extension: Use the LLM to visualize eGFR trends for each patient over time."
  },
  {
    "objectID": "exercises.html#exercise-2-visualization",
    "href": "exercises.html#exercise-2-visualization",
    "title": "Exercises",
    "section": "Exercise 2: Visualization",
    "text": "Exercise 2: Visualization\nPrompt:\nExtension:"
  },
  {
    "objectID": "exercises.html#exercise-3-code",
    "href": "exercises.html#exercise-3-code",
    "title": "Exercises",
    "section": "Exercise 3: Code",
    "text": "Exercise 3: Code\nPrompt:\nExtension:\nhttps://paper-banana.org/"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Untitled",
    "section": "",
    "text": "At this yearâ€™s National Kidney Foundation Spring Clinical Meetings in Boston, Dr.Â @Lili ChanÂ of the Barbara T. Murphy Division of Nephrology and the Windreich Department of Artificial Intelligence and Human Health at the Icahn School of Medicine at Mount Sinai gave a compelling presentation on the integration of artificial intelligence into routine kidney care.\nThe AI Revolution in Kidney Care\nDr.Â Chan began her session by polling the audience on their use of AI in clinical practice, highlighting how artificial intelligence is no longer a futuristic concept-it is increasingly embedded in the day-to-day workflows of healthcare. She organized her presentation around three primary learning objectives:\n\nUnderstanding Natural Language Processing (NLP) and Large Language Models (LLMs)\nReviewing machine learning (ML) applications in clinical care\nDiscussing risks and responsible approaches to AI implementation\n\nTo ground these concepts in clinical relevance, she presented a patient case journey-demonstrating how AI impacts multiple touchpoints, from patients Googling lab results to decision support in clinical encounters and follow-up planning.\nTechnical Foundations: Making AI Understandable\nDr.Â Chan provided an approachable explanation of AIâ€™s inner workings, particularly for attendees less familiar with the technology. She described NLP as the subfield of AI that enables machines to analyze and understand human language, and LLMs as its most sophisticated tools-trained with vast datasets to generate and interpret medical text.\nShe illustrated the vectorization process-how computers convert language into numerical data for processing-using Word2Vec and BERT. The concept of attention mechanisms in transformer models was brought to life with a striking example of the word â€œbark,â€ which has entirely different meanings based on context. These demonstrations helped demystify how AI models contextualize medical language.\nAIâ€™s Clinical Impact: Real-World Examples in Nephrology\nWhat set Dr.Â Chanâ€™s presentation apart was her focus on actionable, real-world applications of AI:\n\nSymptom Detection in Dialysis: Her team showed that AI-driven analysis of clinical notes outperformed patient surveys in identifying symptoms, with sensitivity scores of 0.92 versus 0.58-highlighting AIâ€™s potential to uncover unreported concerns in hemodialysis patients.Â \n\n\n\nAmbient AI Scribes: Data from the Permanente Medical Group demonstrated tangible workflow improvements, including reduced after-hours EHR use, faster documentation, and high-quality note generation (48 out of 50 on scoring metrics).\nAI in Pathology: Dr.Â Chan showcased cutting-edge developments in nephropathology, where AI is used to segment kidney structures, detect interstitial fibrosis, and even predict eGFR decline based on histomorphological data.\n\nPractical Implementation: Prompt Engineering and Use Cases\nFor clinicians ready to experiment with AI tools, Dr.Â Chan introduced best practices in prompt engineering. Her guidance included being specific and clear, setting expectations for tone and output format, and iterating through revisions for optimal results. She encouraged participants to try generating LLM-powered diet recommendations customized for kidney patients, as a hands-on exercise in refining AI prompts.\nBalanced Perspective: Ethical and Practical Cautions\nWhile optimistic about AIâ€™s future in kidney care, Dr.Â Chan was careful to underscore the limitations and ethical concerns:\n\nPrivacy: AI systems often run in the cloud-meaning uploading protected health information (PHI) poses serious risks.\nHallucinations: AI may fabricate content or citations, which necessitates careful cross-verification by clinicians.\nImplementation Barriers: Key challenges include the opaque (â€œblack boxâ€) nature of many models, the need for informed consent, and ensuring AI tools are accessible to all populations.\n\n\nğŸ˜Š Thank for for your wonderful talk, we really enjoyed learning from you @Lili Chan ; my friends/colleagues @Jing Miao @Muhammad Yasir Baloch and I were truly fascinated by your presentation.\nWhat are the most significant obstacles preventing frontline nephrologists from using AI tools regularly? â†’ Time, cost, trust, or lack of training? Happy to hear discussions from you all @Lili Chan @Karin Bergling @Len Usvyat @Kim Solez"
  },
  {
    "objectID": "background.html#integrating-ai-into-everyday-kidney-care-highlights-from-nkf-2025-in-boston",
    "href": "background.html#integrating-ai-into-everyday-kidney-care-highlights-from-nkf-2025-in-boston",
    "title": "Untitled",
    "section": "",
    "text": "At this yearâ€™s National Kidney Foundation Spring Clinical Meetings in Boston, Dr.Â @Lili ChanÂ of the Barbara T. Murphy Division of Nephrology and the Windreich Department of Artificial Intelligence and Human Health at the Icahn School of Medicine at Mount Sinai gave a compelling presentation on the integration of artificial intelligence into routine kidney care.\nThe AI Revolution in Kidney Care\nDr.Â Chan began her session by polling the audience on their use of AI in clinical practice, highlighting how artificial intelligence is no longer a futuristic concept-it is increasingly embedded in the day-to-day workflows of healthcare. She organized her presentation around three primary learning objectives:\n\nUnderstanding Natural Language Processing (NLP) and Large Language Models (LLMs)\nReviewing machine learning (ML) applications in clinical care\nDiscussing risks and responsible approaches to AI implementation\n\nTo ground these concepts in clinical relevance, she presented a patient case journey-demonstrating how AI impacts multiple touchpoints, from patients Googling lab results to decision support in clinical encounters and follow-up planning.\nTechnical Foundations: Making AI Understandable\nDr.Â Chan provided an approachable explanation of AIâ€™s inner workings, particularly for attendees less familiar with the technology. She described NLP as the subfield of AI that enables machines to analyze and understand human language, and LLMs as its most sophisticated tools-trained with vast datasets to generate and interpret medical text.\nShe illustrated the vectorization process-how computers convert language into numerical data for processing-using Word2Vec and BERT. The concept of attention mechanisms in transformer models was brought to life with a striking example of the word â€œbark,â€ which has entirely different meanings based on context. These demonstrations helped demystify how AI models contextualize medical language.\nAIâ€™s Clinical Impact: Real-World Examples in Nephrology\nWhat set Dr.Â Chanâ€™s presentation apart was her focus on actionable, real-world applications of AI:\n\nSymptom Detection in Dialysis: Her team showed that AI-driven analysis of clinical notes outperformed patient surveys in identifying symptoms, with sensitivity scores of 0.92 versus 0.58-highlighting AIâ€™s potential to uncover unreported concerns in hemodialysis patients.Â \n\n\n\nAmbient AI Scribes: Data from the Permanente Medical Group demonstrated tangible workflow improvements, including reduced after-hours EHR use, faster documentation, and high-quality note generation (48 out of 50 on scoring metrics).\nAI in Pathology: Dr.Â Chan showcased cutting-edge developments in nephropathology, where AI is used to segment kidney structures, detect interstitial fibrosis, and even predict eGFR decline based on histomorphological data.\n\nPractical Implementation: Prompt Engineering and Use Cases\nFor clinicians ready to experiment with AI tools, Dr.Â Chan introduced best practices in prompt engineering. Her guidance included being specific and clear, setting expectations for tone and output format, and iterating through revisions for optimal results. She encouraged participants to try generating LLM-powered diet recommendations customized for kidney patients, as a hands-on exercise in refining AI prompts.\nBalanced Perspective: Ethical and Practical Cautions\nWhile optimistic about AIâ€™s future in kidney care, Dr.Â Chan was careful to underscore the limitations and ethical concerns:\n\nPrivacy: AI systems often run in the cloud-meaning uploading protected health information (PHI) poses serious risks.\nHallucinations: AI may fabricate content or citations, which necessitates careful cross-verification by clinicians.\nImplementation Barriers: Key challenges include the opaque (â€œblack boxâ€) nature of many models, the need for informed consent, and ensuring AI tools are accessible to all populations.\n\n\nğŸ˜Š Thank for for your wonderful talk, we really enjoyed learning from you @Lili Chan ; my friends/colleagues @Jing Miao @Muhammad Yasir Baloch and I were truly fascinated by your presentation.\nWhat are the most significant obstacles preventing frontline nephrologists from using AI tools regularly? â†’ Time, cost, trust, or lack of training? Happy to hear discussions from you all @Lili Chan @Karin Bergling @Len Usvyat @Kim Solez"
  },
  {
    "objectID": "background.html#nkf",
    "href": "background.html#nkf",
    "title": "Untitled",
    "section": "NKF",
    "text": "NKF\nAt the 2025 NKF Spring Clinical Meetings, Dr.Â @Navdeep TangriÂ presented an in-depth overview of how predictiveâ€”not generativeâ€”AI is transforming kidney care. As a global thought leader in nephrology innovation, he emphasized supervised machine learningâ€™s (ML) role in accurate, efficient, and scalable clinical predictions.\n\nKey Insights and Applications\nSupervised ML dominates current AI use in nephrology, especially in predicting AKI, CKD progression, and dialysis-related complications.\n\nSimple models still work: Logistic regression often performs nearly as well as complex ML methods for structured datasets.\nImaging-driven AI is powerful: Deep learning excels in pathology and radiology, where it outperforms traditional biopsy interpretations and integrates with NLP to automate disease registries.\nCommercial models are maturing: Tools like Klinrisk and KidneyIntelX are externally validated and used across trials, payers, and health systems.\nIntegration is key: AI must be embedded into the clinical workflow, with transparency, physician leadership, and real-time decision support.\n\n\nThese are the performance metrics of machine learning models in kidney care, as presented in Dr.Â Navdeep Tangriâ€™s NKF 2025 talk. It visualizes key AUC, sensitivity, and specificity values for acute kidney injury (AKI) prediction and intradialytic hypotension (IDH) prediction.\nML for CKD Progression Prediction\nObjective: Improve early identification and risk stratification of patients at risk of rapid CKD progressionâ€”without relying on invasive biomarkers or complex imaging.\n\n\nStrategic Implications for Practice\n\n\n\n\n\n\n\nImplementation Principle\nExample from Talk\n\n\nSimple â‰  Inferior\nKlinrisk uses basic labs but performs as well as complex tools\n\n\nClinical Workflow Integration First\nSONIC/Trajvis are designed for real-time flagging\n\n\nValidate &gt; Invent\nEvery model Dr.Â Tangri supports is externally validated\n\n\nPersonalization Matters\nModels stratify individual risk for resource targeting\n\n\n\nCritical Takeaways from Dr.Â Tangri\n\nDonâ€™t always default to complex MLâ€”many CKD progression problems are solvable with regression models.\nEvaluate models on three axes: Performance, Generalizability, and Clinical Integration.\nDemand external validationâ€”not just ROC curves from a single health system.\nKFRE has limitations in early CKD; new models must cover CKD stages 1â€“5 and at-risk populations.\nTransparency and simplicity matter: Interpretability boosts clinician adoption.\n\nGiven the diversity of CKD patients (by race, SES, comorbidity), how do we ensure model generalizability across health systems and geographies?Â \nHow can we build a national registry of AI model performance across institutions to accelerate benchmarking, transparency, and trust? @Navdeep Tangri @Karandeep Singh @Lili Chan @Girish Nadkarni @Karin Bergling @Kim Solez"
  },
  {
    "objectID": "background.html#aki",
    "href": "background.html#aki",
    "title": "Untitled",
    "section": "AKI",
    "text": "AKI\nThe authors conducted a comprehensive search of PubMed, EMBASE, Web of Science, and Scopus up to August 2023. They screened 4816 articles and ultimately included 95 studies evaluating 302 externally validated ML models for AKI-related outcomes across 3.8 million admissions, covering both adult and pediatric populations.\nKey Findings\n\nğŸ¤” Soâ€¦ Are These Models Ready for the Real World?\nğŸŸ¢ Yes, because:\n\nThey show strong performance in predicting AKI across different settings.\nEven simple models work well (logistic regression = MVP).\nğŸ”´ No, because:\nToo much variation between studies makes results hard to apply at the bedside.\nHigh bias in study design raises concerns.\nNot enough real-world testing in diverse patient groups.\n\nğŸ§­ Where Do We Go From Here?\nTo bring AI into everyday kidney care, we need:\n\nStandardized predictors and outcomes ğŸ“\nMore external validations ğŸ¥\nBetter calibration and user-friendly tools âš™ï¸\nIntegration into clinical workflows with real-time feedback ğŸ‘©â€âš•ï¸ğŸ‘¨â€âš•ï¸\n\nğŸ’¬ Food for Thought:\n\nWhat clinical features would you want an AKI prediction model to consider?\nShould hospitals invest in developing their own local ML models or adopt published ones?\nHow can we balance accuracy with explainability in high-risk predictions?\nWhat would it take for you to trust an AI model with real clinical decisions? @Kim Solez @Karin Bergling @Karandeep Singh @Jay Koyner @Kianoush Kashani"
  },
  {
    "objectID": "background.html#what-i-learned-at-era25-ai-in-nephrology--a-brief-synthesis-from-multiple-sessions-and-therere-more",
    "href": "background.html#what-i-learned-at-era25-ai-in-nephrology--a-brief-synthesis-from-multiple-sessions-and-therere-more",
    "title": "Untitled",
    "section": "ğŸ“˜ What I Learned at #ERA25: AI in Nephrology- A brief synthesis from multiple sessions and thereâ€™re more",
    "text": "ğŸ“˜ What I Learned at #ERA25: AI in Nephrology- A brief synthesis from multiple sessions and thereâ€™re more"
  },
  {
    "objectID": "background.html#reflections-on-the-role-of-ai-in-kidney-care",
    "href": "background.html#reflections-on-the-role-of-ai-in-kidney-care",
    "title": "Untitled",
    "section": "ğŸ¤” Reflections on the Role of AI in Kidney Care",
    "text": "ğŸ¤” Reflections on the Role of AI in Kidney Care\nAt ERA 2025 in Vienna, the conversation around artificial intelligence (AI) in nephrology has clearly evolvedâ€”from curiosity to implementation. This session, CME 9 â€“ Artificial Intelligence for Nephrologists, showcased not just emerging tools but tangible outcomes from AI already being deployed in clinical practice. What stood out was the shift toward practical, integrated applications: systems that predict CKD progression using routine labs, guide anemia management in dialysis, and streamline EMR workflows with large language models. Yet, alongside innovation came important reminders about ethics, governance, and clinician accountability. Below is a structured summary of key insights, tools, and regulatory concerns discussed at the session.Â \n@Valentin Goutaudier @Len Usvyat"
  },
  {
    "objectID": "background.html#foundations-when-and-why-to-use-aiml",
    "href": "background.html#foundations-when-and-why-to-use-aiml",
    "title": "Untitled",
    "section": "ğŸ§  Foundations: When and Why to Use AI/ML",
    "text": "ğŸ§  Foundations: When and Why to Use AI/ML\n\nTalk: AI and Machine Learning Demystified\n\nWhen AI/ML Excels:\n\n\nComplex decision-making (e.g., multi-morbidity)\n\nLarge, multivariate data\n\nHeterogeneous syndromes like CKD\n\nPersonalized careâ€”risk prediction, treatment targeting\n\n\n\n\nKey Benefits:\n\n\nCaptures nonlinear relationships\n\nIntegrates structured + unstructured data\n\nEnables scalable clinical decision support\n\n\n\n\nCore Limitations:\n\n\nSusceptible to biased/poor-quality data\n\nPoor generalizability without external validation\n\nOpaque â€œblack boxâ€ nature â†’ interpretability challenge"
  },
  {
    "objectID": "background.html#ai-tools-in-kidney-care-practice",
    "href": "background.html#ai-tools-in-kidney-care-practice",
    "title": "Untitled",
    "section": "ğŸ§ª AI Tools in Kidney Care Practice",
    "text": "ğŸ§ª AI Tools in Kidney Care Practice\n\nâœ… CKD Progression Prediction with Klinrisk\n\n\nNo EHR or advanced biomarkers needed\n\nUses only routine labs\n\nOutperforms KDIGO and KFRE at 2â€“4 years\n\nAUC up to 0.86 at 4 years\n\nBuilt for population-level monitoring in T2DM patients\n\n\n\n\nğŸ§¬ Kidney Biopsy & Deep Learning\n\n\nAI outperforms manual review in morphologic quantification\n\nPredicts graft loss and segments glomerular lesions\n\n87% of regulatory-cleared AI tools = radiology/pathology\n\n\n\n\nğŸ©¸ AI-Powered Anemia Management\nTool: Anemia Control Model (ACM)\n\n\nActive since 2013 in &gt;100 clinics\n\nDecision support for ESA/iron dosing\n\nOutcomes:\n\n\n25% ESA use reduction\n\n12% lower hospitalization rate\n\n12-year safety track record\n\n\n\n\n\n\nğŸ’» Large Language Models (LLMs) in EMRs\n\n\nGPT-based tools increasingly embedded in EMRs\n\nUse cases:\n\n\nInbox triage\n\nProgress note generation\n\nPrior auths & billing support\n\nPatient-specific reminders between visits"
  },
  {
    "objectID": "background.html#regulatory-ethical-considerations",
    "href": "background.html#regulatory-ethical-considerations",
    "title": "Untitled",
    "section": "âš–ï¸ Regulatory & Ethical Considerations",
    "text": "âš–ï¸ Regulatory & Ethical Considerations\nSpeaker: Dr.Â Pierpaolo Maio\nTalk: AI in Nephrology â€“ Useful or Dangerous? (CON)\n\nRegulatory Frameworks (EU AI Act, MDR, PLD):\n\n\nAI for nephrology = â€œhigh-riskâ€ designation\n\nRequires CE mark, ISO 13485, surveillance\n\nDevelopers + clinicians share legal liability\n\n\n\n\nGovernance Imperatives:\n\n\nMandatory human oversight\n\nTransparent AI logic\n\nHigh-value/low-risk cases prioritized\n\nIncident reporting for AI-related errors mandatory"
  },
  {
    "objectID": "background.html#final-thoughts",
    "href": "background.html#final-thoughts",
    "title": "Untitled",
    "section": "âœ¨ Final Thoughts",
    "text": "âœ¨ Final Thoughts\nAI is transitioning from conceptual hype to practical utility in nephrology. As seen at #ERA25, its applicationsâ€”from CKD prediction and glomerular image analysis to automated ESA dosingâ€”are yielding real-world benefits. However, success hinges on data quality, regulatory compliance, and ongoing clinician oversight.\nThe future of AI in nephrology is not just about algorithmsâ€”it is about responsible integration, trust-building, and ensuring that every decision still begins and ends with the patient.\nThis is just my personal summary of what I learned from the #ERA25 session on AI in nephrology. I may have missed some points, and others might have different takeaways. Feel free to add or share more insights! ğŸ˜ŠğŸ™"
  },
  {
    "objectID": "background.html#how-physicians-can-prepare-for-generative-ai.-jama-internal-medicine-oct-13-2025",
    "href": "background.html#how-physicians-can-prepare-for-generative-ai.-jama-internal-medicine-oct-13-2025",
    "title": "Untitled",
    "section": "â€œHow Physicians Can Prepare for Generative AI.â€ JAMA Internal Medicine, Oct 13, 2025",
    "text": "â€œHow Physicians Can Prepare for Generative AI.â€ JAMA Internal Medicine, Oct 13, 2025\n\nGenerative artificial intelligence (GenAI) is no longer a futuristic concept-it has arrived in clinics, hospitals, and patient portals. While todayâ€™s AI scribes and documentation tools may seem revolutionary, the authors emphasize that these are just the beginning. The next generation of GenAI will not only summarize notes-it will help diagnose, counsel, and even manage clinical conditions. Physicians who understand how to integrate and supervise these systems will lead the transformation of healthcare.\n\n\n\n\n\nUsing AI as a Partner\nTreat AI as a partner, not just a tool. It can reason and communicate but requires clinical oversight and validation.\nPrompting matters. The way a question is framed affects the quality of the response; rephrasing and specifying the AIâ€™s â€œroleâ€ (e.g., â€œYou are an emergency physicianâ€¦â€) can improve accuracy.\nData input quality determines output quality. Clinicians should provide complete, relevant data (e.g., key labs, discharge summaries).\nInteractive learning is key. Physicians should probe chatbot reasoning-ask why and where it obtained information to uncover reasoning flaws.\nClinical Workflow and Responsibility\nGenAI will reshape workflows. Clinicians will shift from writing to editing, as AI scribes generate notes and summaries.\nLegal accountability remains with clinicians. Physicians are responsible for AI-generated documentation until regulatory oversight evolves.\nAI outputs require review. Clinicians must verify accuracy before signing notes or using AI-suggested recommendations.\nFuture FDA oversight will likely extend to documentation and decision-support tools, but clinicians should demand performance validation now.\nEvolving Physicianâ€“Patient Relationship\nPatient expectations are changing. Many patients already use GenAI to interpret symptoms, lab results, and possible diagnoses.\nThe physicianâ€™s role will shift-from sole knowledge authority to expert adjudicator who validates AI- or patient-generated insights.\nHuman skills gain importance. Empathy, physical examination, and shared decision-making will distinguish clinicians from algorithms.\nEducation and Skill Development\nAll clinicians need foundational AI literacy. Understanding how LLMs work is now part of medical competence.\nFormal training is emerging. Institutions like NYU Langone and Harvard offer GenAI prompt training; the American College of Physicians offers short AI courses.\nHands-on experience with safe, HIPAA-compliant tools (e.g., Microsoft Copilot, ChatGPT Enterprise) helps clinicians build confidence.\nEthical literacy is essential. Understanding bias, hallucination, and patient data protection is as important as technical skills.\nFuture Outlook\nGenAI will evolve from assistant to agent. Future â€œagenticâ€ systems may independently collect histories, counsel patients, or generate management plans-requiring new oversight, ethics frameworks, and trials to assess safety and efficacy.\nhttps://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2840192"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data and Generative AI",
    "section": "",
    "text": "Luca Neri, MD, PhD  Renal Research Institute, New York, NY\n\n\n\n\n\nKurtis A. Pivert, MS, CAPX  American Society of Nephrology, Washington, DC\n\n\n\n\n\n\n\n\n9:00 a.m.\nIntroduction, Bias, FASTER\n\n\n9:10 a.m.\nHands-On Exercise 1\n\n\n9:20 a.m.\nHands-On Exercise 2\n\n\n9:30 a.m.\nHands-On Exercise 3\n\n\n9:40 a.m.\nWrap-Up"
  },
  {
    "objectID": "index.html#ai-in-nephrology-hands-on-session",
    "href": "index.html#ai-in-nephrology-hands-on-session",
    "title": "Data and Generative AI",
    "section": "",
    "text": "Luca Neri, MD, PhD  Renal Research Institute, New York, NY\n\n\n\n\n\nKurtis A. Pivert, MS, CAPX  American Society of Nephrology, Washington, DC\n\n\n\n\n\n\n\n\n9:00 a.m.\nIntroduction, Bias, FASTER\n\n\n9:10 a.m.\nHands-On Exercise 1\n\n\n9:20 a.m.\nHands-On Exercise 2\n\n\n9:30 a.m.\nHands-On Exercise 3\n\n\n9:40 a.m.\nWrap-Up"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Prompt Best Practices\n\nThe fundamentals that work across all LLMs:\n\nRole/Persona: Who the AI should act as\nContext: What background info it needs\nTask: What you want it to do explicitly\nFormat: How you want the output structured\nConstraints: What to avoid or limits to follow\n\n\n Source: Reddit: Best Practices for AI Prompting 2025?\n\n\nCO-STAR Prompt Framework\n\nA great prompt usually includes these specific elements to provide context and direction:\n\nContext: Provide background information on the task.\nObjective: Define exactly what you want me to do.\nStyle: Specify a writing style (e.g., professional, humorous, poetic).\nTone: Set the emotional vibe (e.g., empathetic, direct, enthusiastic).\nAudience: Who is this for? (e.g., a CEO, a 5-year-old, a software engineer).\nResponse: Define the format (e.g., a table, a list, a JSON object).\n\nAdditional Components\n\nFew-Shot Prompting/Using Examples: Provide examples of desired output and formatting (e.g., programming language, file type [CSV, Markdown, PNG])\nUse Delimiters:  Use triple quotes (â€œâ€œâ€œ), XML tags (), or dashes (â€”) to wrap your content. (e.g., â€œSummarize the text delimited by triple quotes:â€â€œâ€œ[Insert long article here]â€â€œâ€œâ€)\n\n\n\nSource: Google Gemini (Prompt: do you have any prompt engineering best practices)\n\n\nAdditional Prompt Engineering Resources\n\nAnthropic\n\nPrompt Engineering Guide Overview\nPrompt Engineering Interactive Tutorial\n\n\n\nOpenAI\n\nOpenAI Developers Cookbook\nOpenAI ChatGPT Cookbook\nOpenAI Cookbook Code Repo\nBest Practices for Prompt Engineering with the OpenAI API\nPrompt Engineering\n\n\n\nGoogle\nPrompt engineering: overview and guide\n\n\n10 Best Practices for Prompt Engineering With Any Model\n\nPromptHub\n\n\n\nGitHub: Awesome AI System Prompts\n\nAwesome AI System Prompts"
  },
  {
    "objectID": "resources.html#the-co-star-framework",
    "href": "resources.html#the-co-star-framework",
    "title": "Resources",
    "section": "1. The â€œCO-STARâ€ Framework",
    "text": "1. The â€œCO-STARâ€ Framework\nA great prompt usually includes these specific elements to provide context and direction:\n\nContext: Provide background information on the task.\nObjective: Define exactly what you want me to do.\nStyle: Specify a writing style (e.g., professional, humorous, poetic).\nTone: Set the emotional vibe (e.g., empathetic, direct, enthusiastic).\nAudience: Who is this for? (e.g., a CEO, a 5-year-old, a software engineer).\nResponse: Define the format (e.g., a table, a list, a JSON object)."
  },
  {
    "objectID": "resources.html#be-specific-and-direct",
    "href": "resources.html#be-specific-and-direct",
    "title": "Resources",
    "section": "2. Be Specific and Direct",
    "text": "2. Be Specific and Direct\nAvoid â€œdonâ€™tsâ€ and focus on â€œdos.â€ Negative constraints (e.g., â€œDonâ€™t make it longâ€) are often less effective than positive instructions (e.g., â€œKeep it under 100 wordsâ€).\n\nWeak: â€œWrite something about space.â€\nStrong: â€œWrite a three-paragraph educational summary about the James Webb Space Telescopeâ€™s recent discoveries, intended for high school students.â€"
  },
  {
    "objectID": "resources.html#use-few-shot-prompting",
    "href": "resources.html#use-few-shot-prompting",
    "title": "Resources",
    "section": "3. Use Few-Shot Prompting",
    "text": "3. Use Few-Shot Prompting\nIf you want a very specific output format or style, give me examples. This is known as â€œFew-Shot Prompting.â€\n\nExample: â€œI want you to turn names into funny nicknames. Input: Robert -&gt; Output: Robo-Bob Input: Sarah -&gt; Output: Super-Sass Input: [Your Name] -&gt; Output:â€"
  },
  {
    "objectID": "resources.html#chain-of-thought-cot",
    "href": "resources.html#chain-of-thought-cot",
    "title": "Resources",
    "section": "4. Chain of Thought (CoT)",
    "text": "4. Chain of Thought (CoT)\nFor complex logic, math, or deep analysis, ask me to â€œthink step-by-step.â€ This forces the model to process the logic linearly before arriving at a final answer, which significantly reduces errors."
  },
  {
    "objectID": "resources.html#give-me-a-persona",
    "href": "resources.html#give-me-a-persona",
    "title": "Resources",
    "section": "5. Give Me a Persona",
    "text": "5. Give Me a Persona\nAssigning a role can instantly shift the vocabulary and depth of the response.\n\nâ€œAct as a Senior UX Designer reviewing this landing pageâ€¦â€\nâ€œAct as a skeptical historian evaluating this claimâ€¦â€\nâ€œAct as a supportive personal trainer creating a workout planâ€¦â€"
  },
  {
    "objectID": "resources.html#delimiters-are-your-friends",
    "href": "resources.html#delimiters-are-your-friends",
    "title": "Resources",
    "section": "6. Delimiters are Your Friends",
    "text": "6. Delimiters are Your Friends\nUse punctuation to help me distinguish between my instructions and the data you want me to process.\n\nUse triple quotes (\"\"\"), XML tags (&lt;text&gt;&lt;/text&gt;), or dashes (---) to wrap your content.\n\n\nâ€œSummarize the text delimited by triple quotes:â€â€œâ€œ[Insert long article here]â€â€œâ€œâ€\n\nSource: Google Gemini.\n\nRole/Persona\n\nâ€œYou are aâ€\nâ€œYou are aâ€\n\n\n\nContext\n\nâ€œYou are aâ€\nâ€œYou are aâ€\n\n\n\nTask What you want it to do explicitly\n\nâ€œYou are aâ€\nâ€œYou are aâ€\n\n\n\nFormat\n\nâ€œReturn valid and properly formatted Python code.â€\nâ€œProvide the visualization in both .png and .svg formats.â€\n\n\n\nConstraints\n\nâ€œâ€”Must Doâ€”â€\nâ€œâ€”Do Notâ€”â€"
  },
  {
    "objectID": "resources.html#prompt-resources",
    "href": "resources.html#prompt-resources",
    "title": "Resources",
    "section": "Prompt Resources",
    "text": "Prompt Resources\n\n1. Anthropic\nPrompt Engineering Guide Overview\nPrompt Engineering Interactive Tutorial\n\n\n2. OpenAI\nOpenAI Developers Cookbook OpenAI ChatGPT Cookbook OpenAI Cookbook Code Repo\nBest Practices for Prompt Engineering with the OpenAI API\nPrompt Engineering\n\n\n3. Google\nPrompt engineering: overview and guide\n\n\n4. 10 Best Practices for Prompt Engineering With Any Model\nPromptHub\n\n\n5. Awesome AI System Prompts\nAwesome AI System Prompts"
  }
]